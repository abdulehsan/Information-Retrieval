{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvdQU8bBguGnI3n2wxdRpz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulehsan/Information-Retrieval/blob/main/IR_LAB_(TF_IDF).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation of Vector Space Model**\n"
      ],
      "metadata": {
        "id": "1e0LJy5QKNqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nAA9FpY9HS3g"
      },
      "outputs": [],
      "source": [
        "documents = {\n",
        "    1: \"Information retrieval is the retrieval process of finding relevant documents according to user's information need.\",\n",
        "    2: \"Search engines use indexing for fast retrieval.\",\n",
        "    3: \"An index maps words to document IDs.\",\n",
        "    4: \"Some information retrieval systems don't work optimally because of no text preprocessing\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "sGz0qUm2KauL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6UQ8kLkHfFN",
        "outputId": "fe54bdfa-e726-4cc0-fd80-2e0d148340f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "tBNqiJ4-Hg70"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a preprocessing function that takes the corpus as a argument and perform preprocessing steps like :\n",
        "\n",
        "\n",
        "\n",
        "*   Creating a vocabulary\n",
        "*   Lower case normalization\n",
        "*   Removing Stop words\n",
        "*   Perform Lemmatization\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3_7ct_b-KfW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(doc):\n",
        "\n",
        "  vocab = set()\n",
        "\n",
        "  for line in doc.values():\n",
        "    for word in line.split():\n",
        "      word = re.sub(r'[^\\w\\s]', '', word)\n",
        "      vocab.add(word.lower())\n",
        "      vocab = {word for word in vocab if word not in stop_words}\n",
        "      vocab = {lemmatizer.lemmatize(word) for word in vocab}\n",
        "      # print(vocab)\n",
        "      vocab = {lemmatizer.lemmatize(word,pos='v') for word in vocab}\n",
        "      # # vocab = [token.lemma_ for token in vocab]\n",
        "\n",
        "  return vocab\n",
        "\n",
        "vocab = preprocessing(documents)\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyys5-fNHh02",
        "outputId": "d9396ee3-6696-403b-9df3-af7377a0502f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accord',\n",
              " 'document',\n",
              " 'dont',\n",
              " 'engine',\n",
              " 'fast',\n",
              " 'find',\n",
              " 'id',\n",
              " 'index',\n",
              " 'information',\n",
              " 'map',\n",
              " 'need',\n",
              " 'optimally',\n",
              " 'preprocessing',\n",
              " 'process',\n",
              " 'relevant',\n",
              " 'retrieval',\n",
              " 'search',\n",
              " 'system',\n",
              " 'text',\n",
              " 'use',\n",
              " 'user',\n",
              " 'word',\n",
              " 'work'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Term Frequency Matrix**\n",
        "\n",
        "Steps performed :\n",
        "\n",
        "* Preprocessed and Created a dictionary where keys are the terms , and values are the frequency of their occurence in the document\n"
      ],
      "metadata": {
        "id": "CzCGwXrBLA04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_tf(vocab,doc):\n",
        "  tf = {}\n",
        "\n",
        "  for word in vocab:\n",
        "    tf[word] = []\n",
        "    for line in doc.values():\n",
        "      words = line.split()\n",
        "      words = [re.sub(r'[^\\w\\s]', '', word) for word in words]\n",
        "      words = [word.lower() for word in words if word not in stop_words]\n",
        "      words = [lemmatizer.lemmatize(word) for word in words]\n",
        "      words = [lemmatizer.lemmatize(word,pos='v') for word in words]\n",
        "      tf[word].append(words.count(word))\n",
        "  return tf\n",
        "\n",
        "tf_matrix = cal_tf(vocab,documents)\n",
        "tf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8YMS5E-IWhu",
        "outputId": "c5d39be6-1021-46b0-f030-5da1296a83bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'find': [1, 0, 0, 0],\n",
              " 'dont': [0, 0, 0, 1],\n",
              " 'process': [1, 0, 0, 0],\n",
              " 'text': [0, 0, 0, 1],\n",
              " 'preprocessing': [0, 0, 0, 1],\n",
              " 'map': [0, 0, 1, 0],\n",
              " 'relevant': [1, 0, 0, 0],\n",
              " 'optimally': [0, 0, 0, 1],\n",
              " 'search': [0, 1, 0, 0],\n",
              " 'engine': [0, 1, 0, 0],\n",
              " 'system': [0, 0, 0, 1],\n",
              " 'id': [0, 0, 1, 0],\n",
              " 'use': [0, 1, 0, 0],\n",
              " 'index': [0, 1, 1, 0],\n",
              " 'fast': [0, 1, 0, 0],\n",
              " 'accord': [1, 0, 0, 0],\n",
              " 'retrieval': [2, 1, 0, 1],\n",
              " 'need': [1, 0, 0, 0],\n",
              " 'work': [0, 0, 0, 1],\n",
              " 'word': [0, 0, 1, 0],\n",
              " 'user': [1, 0, 0, 0],\n",
              " 'document': [1, 0, 1, 0],\n",
              " 'information': [2, 0, 0, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a weighted term frequency matrix**\n",
        "\n",
        "* Terms as a key and 1 + log(tf) as value"
      ],
      "metadata": {
        "id": "lhKsFGYYLZ6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_tf_log_matrix(tf_matrix):\n",
        "  tf_log_matrix = {}\n",
        "\n",
        "  for key,value in tf_matrix.items():\n",
        "    tf_log_matrix[key] = []\n",
        "    for i in value:\n",
        "      if i > 0:\n",
        "        tf_log_matrix[key].append(1 + math.log10(i))\n",
        "      else:\n",
        "        tf_log_matrix[key].append(0)\n",
        "  return tf_log_matrix\n",
        "tf_log_matrix = cal_tf_log_matrix(tf_matrix)\n",
        "tf_log_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsDGXaZkJLVs",
        "outputId": "ccfdd0ed-f89b-4b42-a962-e22b516b78da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'find': [1.0, 0, 0, 0],\n",
              " 'dont': [0, 0, 0, 1.0],\n",
              " 'process': [1.0, 0, 0, 0],\n",
              " 'text': [0, 0, 0, 1.0],\n",
              " 'preprocessing': [0, 0, 0, 1.0],\n",
              " 'map': [0, 0, 1.0, 0],\n",
              " 'relevant': [1.0, 0, 0, 0],\n",
              " 'optimally': [0, 0, 0, 1.0],\n",
              " 'search': [0, 1.0, 0, 0],\n",
              " 'engine': [0, 1.0, 0, 0],\n",
              " 'system': [0, 0, 0, 1.0],\n",
              " 'id': [0, 0, 1.0, 0],\n",
              " 'use': [0, 1.0, 0, 0],\n",
              " 'index': [0, 1.0, 1.0, 0],\n",
              " 'fast': [0, 1.0, 0, 0],\n",
              " 'accord': [1.0, 0, 0, 0],\n",
              " 'retrieval': [1.3010299956639813, 1.0, 0, 1.0],\n",
              " 'need': [1.0, 0, 0, 0],\n",
              " 'work': [0, 0, 0, 1.0],\n",
              " 'word': [0, 0, 1.0, 0],\n",
              " 'user': [1.0, 0, 0, 0],\n",
              " 'document': [1.0, 0, 1.0, 0],\n",
              " 'information': [1.3010299956639813, 0, 0, 1.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating idf matrix**\n",
        "\n",
        "* Defining a function for IDF matrix that takes the vocabulary and tf matrix as argument\n",
        "\n",
        "* Created a dictionary where keys are terms and value are log(N/df) where N is the total number of documents which in this case is 4 , df is the document frequency"
      ],
      "metadata": {
        "id": "bdnncN_ALnCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_idf(vocab,tf_matrix,doc):\n",
        "\n",
        "  idf_matrix = {}\n",
        "\n",
        "  for word in vocab:\n",
        "    idf_matrix[word] = 0\n",
        "    for key,value in tf_matrix.items():\n",
        "      count = 0\n",
        "      if key == word:\n",
        "        for i in value:\n",
        "          if i > 0:\n",
        "            count += 1\n",
        "        idf_matrix[word]=math.log10(len(doc)/(count))\n",
        "  return idf_matrix\n",
        "\n",
        "idf_matrix = cal_idf(vocab,tf_matrix,documents)\n",
        "idf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSusLwYIJW78",
        "outputId": "e1fe9d88-9548-43d9-8216-a8fec283e866"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'find': 0.6020599913279624,\n",
              " 'dont': 0.6020599913279624,\n",
              " 'process': 0.6020599913279624,\n",
              " 'text': 0.6020599913279624,\n",
              " 'preprocessing': 0.6020599913279624,\n",
              " 'map': 0.6020599913279624,\n",
              " 'relevant': 0.6020599913279624,\n",
              " 'optimally': 0.6020599913279624,\n",
              " 'search': 0.6020599913279624,\n",
              " 'engine': 0.6020599913279624,\n",
              " 'system': 0.6020599913279624,\n",
              " 'id': 0.6020599913279624,\n",
              " 'use': 0.6020599913279624,\n",
              " 'index': 0.3010299956639812,\n",
              " 'fast': 0.6020599913279624,\n",
              " 'accord': 0.6020599913279624,\n",
              " 'retrieval': 0.12493873660829992,\n",
              " 'need': 0.6020599913279624,\n",
              " 'work': 0.6020599913279624,\n",
              " 'word': 0.6020599913279624,\n",
              " 'user': 0.6020599913279624,\n",
              " 'document': 0.3010299956639812,\n",
              " 'information': 0.3010299956639812}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a tf-idf matrix**\n",
        "\n",
        "* Created a dictionary for tf-idf matrix where keys are terms and values are tf.idf values ( Multiplying tf and idf values )"
      ],
      "metadata": {
        "id": "RdvOh5beMNAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_tf_idf_matrix(tf_log_matrix,idf):\n",
        "  tf_idf_matrix = {}\n",
        "\n",
        "  for key,value in tf_log_matrix.items():\n",
        "    tf_idf_matrix[key] = []\n",
        "    for i in value:\n",
        "      tf_idf_matrix[key].append(i*idf[key])\n",
        "  return tf_idf_matrix\n",
        "\n",
        "tf_idf_matrix = cal_tf_idf_matrix(tf_log_matrix,idf_matrix)\n",
        "tf_idf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50hszGqEJs-5",
        "outputId": "76be0dcc-5d17-4ab1-bb84-2384bb31bb3f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'find': [0.6020599913279624, 0.0, 0.0, 0.0],\n",
              " 'dont': [0.0, 0.0, 0.0, 0.6020599913279624],\n",
              " 'process': [0.6020599913279624, 0.0, 0.0, 0.0],\n",
              " 'text': [0.0, 0.0, 0.0, 0.6020599913279624],\n",
              " 'preprocessing': [0.0, 0.0, 0.0, 0.6020599913279624],\n",
              " 'map': [0.0, 0.0, 0.6020599913279624, 0.0],\n",
              " 'relevant': [0.6020599913279624, 0.0, 0.0, 0.0],\n",
              " 'optimally': [0.0, 0.0, 0.0, 0.6020599913279624],\n",
              " 'search': [0.0, 0.6020599913279624, 0.0, 0.0],\n",
              " 'engine': [0.0, 0.6020599913279624, 0.0, 0.0],\n",
              " 'system': [0.0, 0.0, 0.0, 0.6020599913279624],\n",
              " 'id': [0.0, 0.0, 0.6020599913279624, 0.0],\n",
              " 'use': [0.0, 0.6020599913279624, 0.0, 0.0],\n",
              " 'index': [0.0, 0.3010299956639812, 0.3010299956639812, 0.0],\n",
              " 'fast': [0.0, 0.6020599913279624, 0.0, 0.0],\n",
              " 'accord': [0.6020599913279624, 0.0, 0.0, 0.0],\n",
              " 'retrieval': [0.16254904394775974,\n",
              "  0.12493873660829992,\n",
              "  0.0,\n",
              "  0.12493873660829992],\n",
              " 'need': [0.6020599913279624, 0.0, 0.0, 0.0],\n",
              " 'work': [0.0, 0.0, 0.0, 0.6020599913279624],\n",
              " 'word': [0.0, 0.0, 0.6020599913279624, 0.0],\n",
              " 'user': [0.6020599913279624, 0.0, 0.0, 0.0],\n",
              " 'document': [0.3010299956639812, 0.0, 0.3010299956639812, 0.0],\n",
              " 'information': [0.39164905395343774, 0.0, 0.0, 0.3010299956639812]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query Processing**\n",
        "\n",
        "* Peroforming Preprocessing\n",
        "* Calculating tf of query\n",
        "* Calculating weighted tf of query\n",
        "* Calculating tf-idf of query\n"
      ],
      "metadata": {
        "id": "8kgW4uzrMeP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Information Retrieval Processes\"\n",
        "\n",
        "query_vocab = vocab\n",
        "\n",
        "query_tf = cal_tf(query_vocab, {1: query})\n",
        "\n",
        "query_tf_log = cal_tf_log_matrix(query_tf)\n",
        "\n",
        "query_tf_idf = {}\n",
        "for term in query_vocab:\n",
        "    query_tf_idf[term] = [query_tf_log[term][0] * idf_matrix.get(term, 0)]\n",
        "\n",
        "query_tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqU1o8wBJxVX",
        "outputId": "3b1116fb-33b3-41b5-e268-de346d2c3496"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'find': [0.0],\n",
              " 'dont': [0.0],\n",
              " 'process': [0.6020599913279624],\n",
              " 'text': [0.0],\n",
              " 'preprocessing': [0.0],\n",
              " 'map': [0.0],\n",
              " 'relevant': [0.0],\n",
              " 'optimally': [0.0],\n",
              " 'search': [0.0],\n",
              " 'engine': [0.0],\n",
              " 'system': [0.0],\n",
              " 'id': [0.0],\n",
              " 'use': [0.0],\n",
              " 'index': [0.0],\n",
              " 'fast': [0.0],\n",
              " 'accord': [0.0],\n",
              " 'retrieval': [0.12493873660829992],\n",
              " 'need': [0.0],\n",
              " 'work': [0.0],\n",
              " 'word': [0.0],\n",
              " 'user': [0.0],\n",
              " 'document': [0.0],\n",
              " 'information': [0.3010299956639812]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(vector1, vector2):\n",
        "  \"\"\"Calculates the cosine similarity between two vectors.\"\"\"\n",
        "  dot_product = np.dot(vector1, vector2)\n",
        "  magnitude1 = np.linalg.norm(vector1)\n",
        "  magnitude2 = np.linalg.norm(vector2)\n",
        "  similarity = dot_product / (magnitude1 * magnitude2)\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "fKcZXt6iK3YX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors = []\n",
        "for doc_id in range(1, len(documents) + 1):\n",
        "    doc_vector = []\n",
        "    for term in query_vocab:  # Ensure order matches query_tf_idf\n",
        "        tf_idf_value = tf_idf_matrix.get(term, [0] * len(documents))[doc_id - 1]\n",
        "        doc_vector.append(tf_idf_value)\n",
        "    doc_vectors.append(doc_vector)\n",
        "\n",
        "query_vector = [query_tf_idf.get(term, [0])[0] for term in query_vocab] # Ensure order matches doc_vectors"
      ],
      "metadata": {
        "id": "HD1DLcaZK7JE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query_vector = list(query_tf_idf.values())[0]"
      ],
      "metadata": {
        "id": "20ShhXbTK8sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate cosine similarity for each document\n",
        "similarities = {}\n",
        "for i, doc_vector in enumerate(doc_vectors):\n",
        "  similarity = cosine_similarity(query_vector, doc_vector)\n",
        "  similarities[i+1] = similarity  # Store similarity with document ID\n",
        "\n",
        "# Rank documents based on similarity (descending order)\n",
        "ranked_documents = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Display the ranked documents\n",
        "print(\"Ranked Documents:\")\n",
        "for doc_id, similarity in ranked_documents:\n",
        "  print(f\"Document {doc_id}: Similarity = {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfMFZeTUK-Ta",
        "outputId": "96d88985-a9e0-4040-c6b0-3b0dcd652df4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Documents:\n",
            "Document 1: Similarity = 0.46767925108253683\n",
            "Document 4: Similarity = 0.10273571045099146\n",
            "Document 2: Similarity = 0.018277676453873085\n",
            "Document 3: Similarity = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "In this notebook we implemented Ranked Retrieval , Vector Space Model\n",
        "\n",
        "* First of all we created a vocabulary for corpus\n",
        "* Applied Preprocessing ( Removing Stop words , Normalization , Lemmatizaton )\n",
        "* Created TF Matrix\n",
        "* Created TF weighted Matrix by logarithm\n",
        "* Created IDF Matrix\n",
        "* Created TF.IDF Matrix\n",
        "\n",
        "* Created TF.IDF Matrix for query\n",
        "\n",
        "* Calculate Cosine Similarity for Ranked Retrieving\n",
        "\n",
        "Key FIndings:\n",
        "\n",
        "* If a word is present in query and not present in vocabulary then the idf of that term will be zero , it will be out of vocabulary term , so it will not collaborate in calculating cosine similarity.\n",
        "\n",
        "* The lemmatizer using Wordnet by default lemmatize noun .\n",
        "* To Lemmatize verbs we have to pass 'pos' parameter to the function with the value v"
      ],
      "metadata": {
        "id": "0PB0Mkq1dMAF"
      }
    }
  ]
}